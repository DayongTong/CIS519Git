{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1\n",
    "This is the template for the first homework assignment.\n",
    "The only function that you are required to fill in and turn in to Gradescope is \"compute_features\".\n",
    "Please do not edit definition of \"compute_features\" so the Gradescope unit tests run successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment and run this code if you want to verify your `sklearn` installation.\n",
    "# If this cell outputs 'array([1])', then it's installed correctly.\n",
    "\n",
    "# from sklearn import tree\n",
    "# X = [[0, 0], [1, 1]]\n",
    "# y = [0, 1]\n",
    "# clf = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "# clf = clf.fit(X, y)\n",
    "# clf.predict([[2, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"madelon/train/X_train.npy\")\n",
    "y_train = np.load(\"madelon/train/Y_train.npy\")\n",
    "X_test = np.load(\"madelon/test/X_test.npy\")\n",
    "y_test = np.load(\"madelon/test/Y_test.npy\")\n",
    "# X_train1 = np."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sdg_train_accuracy,sdg_test_accuracy,sdg_trained_model = train_and_evaluate_sgd(x_train,y_train,x_test,y_test) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.595\n"
     ]
    }
   ],
   "source": [
    "# sdg model full train and test set\n",
    "\n",
    "sgd_model = SGDClassifier(loss = 'log', max_iter = 10000)\n",
    "sgd_model = sgd_model.fit(X_train,y_train)\n",
    "sgd_model.predict(X_test)\n",
    "sgd_testing_accuracy = sgd_model.score(X_test,y_test)\n",
    "print(sgd_testing_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation of Sgd\n",
    "\n",
    "k = 5\n",
    "acc_train_sgd = np.zeros(k)\n",
    "acc_heldout_sgd = np.zeros(k)\n",
    "for i in range(k):\n",
    "\n",
    "    X_heldout_cv_fileloc = \"madelon/cross_validation/cv-heldout-X.\" + str(i) + \".npy\"\n",
    "    X_heldout_cv = np.load(X_heldout_cv_fileloc)\n",
    "    y_heldout_cv_fileloc = \"madelon/cross_validation/cv-heldout-y.\" + str(i) + \".npy\"\n",
    "    y_heldout_cv = np.load(y_heldout_cv_fileloc)\n",
    "    X_train_cv_fileloc = \"madelon/cross_validation/cv-train-X.\" + str(i) + \".npy\"\n",
    "    X_train_cv = np.load(X_train_cv_fileloc)\n",
    "    y_train_cv_fileloc = \"madelon/cross_validation/cv-train-y.\" + str(i) + \".npy\"\n",
    "    y_train_cv = np.load(y_train_cv_fileloc)\n",
    "\n",
    "    sgd_model = SGDClassifier(loss = 'log', max_iter = 10000)\n",
    "    sgd_model = sgd_model.fit(X_train_cv,y_train_cv)\n",
    "    acc_train_sgd[i] = sgd_model.score(X_train_cv,y_train_cv)\n",
    "    acc_heldout_sgd[i] = sgd_model.score(X_heldout_cv,y_heldout_cv)\n",
    "\n",
    "std_train_sgd = np.std(acc_train_sgd)\n",
    "std_heldout_sgd = np.std(acc_heldout_sgd)\n",
    "acc_train_sgd_avg = np.average(acc_train_sgd)\n",
    "acc_heldout_sgd_avg = np.average(acc_heldout_sgd)\n",
    "CI_train_sgd = [acc_train_sgd_avg - 2.571 * np.std(acc_train_sgd) / np.sqrt(k),\\\n",
    "                acc_train_sgd_avg + 2.571 * np.std(acc_train_sgd) / np.sqrt(k)]\n",
    "CI_heldout_sgd = [acc_heldout_sgd_avg - 2.571 * np.std(acc_heldout_sgd) / np.sqrt(k),\\\n",
    "                  acc_heldout_sgd_avg + 2.571 * np.std(acc_heldout_sgd) / np.sqrt(k)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76488095 0.76964286 0.72738095 0.82202381 0.7547619 ]\n",
      "[0.55714286 0.65714286 0.55       0.54761905 0.59285714]\n",
      "0.7677380952380952\n",
      "0.580952380952381\n",
      "[0.7322776364509058, 0.8031985540252846]\n",
      "[0.5333152365958079, 0.6285895253089541]\n"
     ]
    }
   ],
   "source": [
    "print(acc_train_sgd)\n",
    "print(acc_heldout_sgd)\n",
    "print(acc_train_sgd_avg)\n",
    "print(acc_heldout_sgd_avg)\n",
    "print(CI_train_sgd)\n",
    "print(CI_heldout_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.67\n"
     ]
    }
   ],
   "source": [
    "# decision tree full train and test set\n",
    "\n",
    "dectree_model = DecisionTreeClassifier(criterion='entropy')\n",
    "dectree_model = dectree_model.fit(X_train,y_train)\n",
    "dectree_model.predict(X_test)\n",
    "dectree_testing_accuracy = dectree_model.score(X_test,y_test)\n",
    "print(dectree_testing_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree cross validation\n",
    "\n",
    "k = 5\n",
    "acc_train_dectree = np.zeros(k)\n",
    "acc_heldout_dectree = np.zeros(k)\n",
    "for i in range(k):\n",
    "    \n",
    "    X_train_cv_fileloc = \"madelon/cross_validation/cv-train-X.\" + str(i) + \".npy\"\n",
    "    X_train_cv = np.load(X_train_cv_fileloc)\n",
    "    y_train_cv_fileloc = \"madelon/cross_validation/cv-train-y.\" + str(i) + \".npy\"\n",
    "    y_train_cv = np.load(y_train_cv_fileloc)\n",
    "    X_heldout_cv_fileloc = \"madelon/cross_validation/cv-heldout-X.\" + str(i) + \".npy\"\n",
    "    X_heldout_cv = np.load(X_heldout_cv_fileloc)\n",
    "    y_heldout_cv_fileloc = \"madelon/cross_validation/cv-heldout-y.\" + str(i) + \".npy\"\n",
    "    y_heldout_cv = np.load(y_heldout_cv_fileloc)\n",
    "    \n",
    "    dectree_model = DecisionTreeClassifier(criterion='entropy')\n",
    "    dectree_model = dectree_model.fit(X_train_cv,y_train_cv)\n",
    "    acc_train_dectree[i] = dectree_model.score(X_train_cv,y_train_cv)\n",
    "    acc_heldout_dectree[i] = dectree_model.score(X_heldout_cv,y_heldout_cv)\n",
    "\n",
    "std_train_dectree = np.std(acc_train_dectree)\n",
    "std_heldout_dectree = np.std(acc_heldout_dectree)\n",
    "acc_train_dectree_avg = np.average(acc_train_dectree)\n",
    "acc_heldout_dectree_avg = np.average(acc_heldout_dectree)\n",
    "CI_train_dectree = [acc_train_dectree_avg - 2.571 * np.std(acc_train_dectree) / np.sqrt(k),\\\n",
    "                acc_train_dectree_avg + 2.571 * np.std(acc_train_dectree) / np.sqrt(k)]\n",
    "CI_heldout_dectree = [acc_heldout_dectree_avg - 2.571 * np.std(acc_heldout_dectree) / np.sqrt(k),\\\n",
    "                  acc_heldout_dectree_avg + 2.571 * np.std(acc_heldout_dectree) / np.sqrt(k)]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "[0.63809524 0.71666667 0.66904762 0.68333333 0.65      ]\n",
      "1.0\n",
      "0.6714285714285715\n",
      "[1.0, 1.0]\n",
      "[0.6398809354034188, 0.7029762074537241]\n"
     ]
    }
   ],
   "source": [
    "print(acc_train_dectree)\n",
    "print(acc_heldout_dectree)\n",
    "print(acc_train_dectree_avg)\n",
    "print(acc_heldout_dectree_avg)\n",
    "print(CI_train_dectree)\n",
    "print(CI_heldout_dectree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.71\n"
     ]
    }
   ],
   "source": [
    "# stump decision tree full train and test set\n",
    "\n",
    "decstump_model = DecisionTreeClassifier(criterion='entropy', max_depth=4)\n",
    "decstump_model = decstump_model.fit(X_train,y_train)\n",
    "temp = decstump_model.predict(X_test)\n",
    "decstump_testing_accuracy = decstump_model.score(X_test,y_test)\n",
    "print(decstump_testing_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stump decision tree full cross validation\n",
    "\n",
    "k = 5\n",
    "acc_train_decstump = np.zeros(k)\n",
    "acc_heldout_decstump = np.zeros(k)\n",
    "for i in range(k):\n",
    "    \n",
    "    X_train_cv_fileloc = \"madelon/cross_validation/cv-train-X.\" + str(i) + \".npy\"\n",
    "    X_train_cv = np.load(X_train_cv_fileloc)\n",
    "    y_train_cv_fileloc = \"madelon/cross_validation/cv-train-y.\" + str(i) + \".npy\"\n",
    "    y_train_cv = np.load(y_train_cv_fileloc)\n",
    "    X_heldout_cv_fileloc = \"madelon/cross_validation/cv-heldout-X.\" + str(i) + \".npy\"\n",
    "    X_heldout_cv = np.load(X_heldout_cv_fileloc)\n",
    "    y_heldout_cv_fileloc = \"madelon/cross_validation/cv-heldout-y.\" + str(i) + \".npy\"\n",
    "    y_heldout_cv = np.load(y_heldout_cv_fileloc)\n",
    "    \n",
    "    decstump_model = DecisionTreeClassifier(criterion='entropy', max_depth=4)\n",
    "    decstump_model = decstump_model.fit(X_train_cv,y_train_cv)\n",
    "    acc_train_decstump[i] = decstump_model.score(X_train_cv,y_train_cv)\n",
    "    acc_heldout_decstump[i] = decstump_model.score(X_heldout_cv,y_heldout_cv)\n",
    "\n",
    "std_train_decstump = np.std(acc_train_decstump)\n",
    "std_heldout_decstump = np.std(acc_heldout_decstump)\n",
    "acc_train_decstump_avg = np.average(acc_train_decstump)\n",
    "acc_heldout_decstump_avg = np.average(acc_heldout_decstump)\n",
    "CI_train_decstump = [acc_train_decstump_avg - 2.571 * np.std(acc_train_decstump) / np.sqrt(k),\\\n",
    "                acc_train_decstump_avg + 2.571 * np.std(acc_train_decstump) / np.sqrt(k)]\n",
    "CI_heldout_decstump = [acc_heldout_decstump_avg - 2.571 * np.std(acc_heldout_decstump) / np.sqrt(k),\\\n",
    "                  acc_heldout_decstump_avg + 2.571 * np.std(acc_heldout_decstump) / np.sqrt(k)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76369048 0.74880952 0.75654762 0.76904762 0.76904762]\n",
      "[0.72142857 0.68333333 0.7047619  0.6952381  0.71666667]\n",
      "0.7614285714285713\n",
      "0.7042857142857143\n",
      "[0.7524590595683749, 0.7703980832887678]\n",
      "[0.6882854662519226, 0.720285962319506]\n"
     ]
    }
   ],
   "source": [
    "print(acc_train_decstump)\n",
    "print(acc_heldout_decstump)\n",
    "print(acc_train_decstump_avg)\n",
    "print(acc_heldout_decstump_avg)\n",
    "print(CI_train_decstump)\n",
    "print(CI_heldout_decstump)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hybrid model training accuracy 0.861904761904762\n",
      "hybrid model testing accuracy 0.775\n"
     ]
    }
   ],
   "source": [
    "# # hybrid model full train and test set\n",
    "\n",
    "M = X_train.shape[1]      #number of features\n",
    "tree_num = 100      #number of trees as features\n",
    "# initialize a N by tree_num as new X_train made of outputs from 100 trees\n",
    "X_train_treefeature = np.empty([X_train.shape[0],tree_num])   \n",
    "forest = []\n",
    "feature_indexes = np.empty([tree_num,int(M/2)])\n",
    "# train 100 stumps per example as features\n",
    "for i in range(tree_num):\n",
    "    index_vec = list(range(M))\n",
    "    for j in range(int(M/2)):\n",
    "        index_vec.pop(random.randrange(0,int(M/2)))\n",
    "    X_train_sub = np.delete(X_train,index_vec,1)\n",
    "    newstump = DecisionTreeClassifier(criterion='entropy',max_depth=4)\n",
    "    newstump = newstump.fit(X_train_sub,y_train)\n",
    "    X_train_treefeature[:,i] = newstump.predict(X_train_sub)   #output x predictions\n",
    "    forest.append(newstump)     #output new tree stump classifier\n",
    "    feature_indexes[i,:] = index_vec      #output feature indexes for this tree\n",
    "\n",
    "# apply the stump modified X_train to the sgd classifier\n",
    "sgd_hybrid = SGDClassifier(loss = 'log', max_iter = 10000)\n",
    "sgd_hybrid = sgd_hybrid.fit(X_train_treefeature,y_train)\n",
    "\n",
    "# convert X_test to treefeature and test accuracy on test set\n",
    "X_test_treefeature = np.empty([X_test.shape[0],tree_num])\n",
    "index_vec = feature_indexes.astype(int)\n",
    "\n",
    "for i in range(tree_num):\n",
    "    X_test_sub = np.delete(X_test,index_vec[i,:],1)\n",
    "    X_test_treefeature[:,i] = forest[i].predict(X_test_sub)\n",
    "sgd_hybrid.predict(X_test_treefeature)\n",
    "sgd_hybrid_training_accuracy = sgd_hybrid.score(X_train_treefeature,y_train)\n",
    "sgd_hybrid_testing_accuracy = sgd_hybrid.score(X_test_treefeature,y_test)\n",
    "print('hybrid model training accuracy ' + str(sgd_hybrid_training_accuracy))\n",
    "print('hybrid model testing accuracy ' + str(sgd_hybrid_testing_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use hybrid training function to do cross validation\n",
    "\n",
    "k = 5\n",
    "acc_train_hybrid = np.zeros(k)\n",
    "acc_heldout_hybrid = np.zeros(k)\n",
    "for i in range(k):\n",
    "    X_train_cv_fileloc = \"madelon/cross_validation/cv-train-X.\" + str(i) + \".npy\"\n",
    "    X_train_cv = np.load(X_train_cv_fileloc)\n",
    "    y_train_cv_fileloc = \"madelon/cross_validation/cv-train-y.\" + str(i) + \".npy\"\n",
    "    y_train_cv = np.load(y_train_cv_fileloc)\n",
    "    X_heldout_cv_fileloc = \"madelon/cross_validation/cv-heldout-X.\" + str(i) + \".npy\"\n",
    "    X_heldout_cv = np.load(X_heldout_cv_fileloc)\n",
    "    y_heldout_cv_fileloc = \"madelon/cross_validation/cv-heldout-y.\" + str(i) + \".npy\"\n",
    "    y_heldout_cv = np.load(y_heldout_cv_fileloc)\n",
    "    acc_train_hybrid[i],acc_heldout_hybrid[i],sgd_hybrid = train_hybrid_model(X_train_cv,y_train_cv,\\\n",
    "                                                                              X_heldout_cv,y_heldout_cv)\n",
    "\n",
    "std_train_hybrid = np.std(acc_train_hybrid)\n",
    "std_heldout_hybrid = np.std(acc_heldout_hybrid)\n",
    "acc_train_hybrid_avg = np.average(acc_train_hybrid)\n",
    "acc_heldout_hybrid_avg = np.average(acc_heldout_hybrid)\n",
    "CI_train_hybrid = [acc_train_hybrid_avg - 2.571 * np.std(acc_train_hybrid) / np.sqrt(k),\\\n",
    "                acc_train_hybrid_avg + 2.571 * np.std(acc_train_hybrid) / np.sqrt(k)]\n",
    "CI_heldout_hybrid = [acc_heldout_hybrid_avg - 2.571 * np.std(acc_heldout_hybrid) / np.sqrt(k),\\\n",
    "                  acc_heldout_hybrid_avg + 2.571 * np.std(acc_heldout_hybrid) / np.sqrt(k)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88154762 0.87083333 0.86904762 0.87083333 0.85535714]\n",
      "[0.7952381  0.76428571 0.74761905 0.71666667 0.76190476]\n",
      "0.8695238095238095\n",
      "0.7571428571428571\n",
      "[0.859918821879202, 0.879128797168417]\n",
      "[0.7278110562629735, 0.7864746580227407]\n"
     ]
    }
   ],
   "source": [
    "print(acc_train_hybrid)\n",
    "print(acc_heldout_hybrid)\n",
    "print(acc_train_hybrid_avg)\n",
    "print(acc_heldout_hybrid_avg)\n",
    "print(CI_train_hybrid)\n",
    "print(CI_heldout_hybrid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the results\n",
    "\n",
    "plot_results(acc_train_sgd_avg, std_train_sgd, acc_heldout_sgd_avg, std_heldout_sgd, sgd_testing_accuracy,\n",
    "             acc_train_dectree_avg, std_train_dectree, acc_heldout_dectree_avg, std_heldout_dectree, dectree_testing_accuracy,\n",
    "             acc_train_decstump_avg, std_train_decstump, acc_heldout_decstump_avg, std_heldout_decstump, decstump_testing_accuracy,\n",
    "             acc_train_hybrid_avg, std_train_hybrid, acc_heldout_hybrid_avg, std_heldout_hybrid, sgd_hybrid_testing_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import leaderboard data and predict it\n",
    "\n",
    "X_leaderboard = np.load(\"madelon/leaderboard/X_leaderboard.npy\")\n",
    "X_leaderboard_treefeature = np.empty([X_leaderboard.shape[0],100])\n",
    "index_vec = feature_indexes.astype(int)\n",
    "for i in range(tree_num):\n",
    "    X_leaderboard_sub = np.delete(X_leaderboard,index_vec[i,:],1)\n",
    "    X_leaderboard_treefeature[:,i] = forest[i].predict(X_leaderboard_sub)\n",
    "Leaderboard_predict = sgd_hybrid.predict(X_leaderboard_treefeature)\n",
    "filename = 'labels_2a_leaderboard'\n",
    "np.savetxt(\"{}.txt\".format(filename), Leaderboard_predict, fmt='%i', newline=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import hidden data and predict it\n",
    "\n",
    "X_hidden = np.load(\"madelon/hidden/X_hidden.npy\")\n",
    "X_hidden_treefeature = np.empty([X_hidden.shape[0],100])\n",
    "index_vec = feature_indexes.astype(int)\n",
    "for i in range(tree_num):\n",
    "    X_hidden_sub = np.delete(X_hidden,index_vec[i,:],1)\n",
    "    X_hidden_treefeature[:,i] = forest[i].predict(X_hidden_sub)\n",
    "Hidden_predict = sgd_hybrid.predict(X_hidden_treefeature)\n",
    "filename = 'labels_2a_hidden'\n",
    "np.savetxt(\"{}.txt\".format(filename), Hidden_predict, fmt='%i', newline=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_hybrid_model(X_train, y_train, X_test, y_test):\n",
    "    # hybrid model full train and test set\n",
    "\n",
    "    M = X_train.shape[1]      #number of features\n",
    "    tree_num = 100      #number of trees as features\n",
    "    # initialize a N by tree_num as new X_train made of outputs from 100 trees\n",
    "    X_train_treefeature = np.empty([X_train.shape[0],tree_num])   \n",
    "    forest = []\n",
    "    feature_indexes = np.empty([tree_num,int(M/2)])\n",
    "    # train 100 stumps per example as features\n",
    "    for i in range(tree_num):\n",
    "        index_vec = list(range(M))\n",
    "        for j in range(int(M/2)):\n",
    "            index_vec.pop(random.randrange(0,int(M/2)))\n",
    "        X_train_sub = np.delete(X_train,index_vec,1)\n",
    "        newstump = DecisionTreeClassifier(criterion='entropy',max_depth=4)\n",
    "        newstump = newstump.fit(X_train_sub,y_train)\n",
    "        X_train_treefeature[:,i] = newstump.predict(X_train_sub)   #output x predictions\n",
    "        forest.append(newstump)     #output new tree stump classifier\n",
    "        feature_indexes[i,:] = index_vec      #output feature indexes for this tree\n",
    "\n",
    "    # apply the stump modified X_train to the sgd classifier\n",
    "    sgd_hybrid = SGDClassifier(loss = 'log', max_iter = 10000)\n",
    "    sgd_hybrid = sgd_hybrid.fit(X_train_treefeature,y_train)\n",
    "\n",
    "    # convert X_test to treefeature and test accuracy on test set\n",
    "    X_test_treefeature = np.empty([X_test.shape[0],tree_num])\n",
    "    index_vec = feature_indexes.astype(int)\n",
    "\n",
    "    for i in range(tree_num):\n",
    "        X_test_sub = np.delete(X_test,index_vec[i,:],1)\n",
    "        X_test_treefeature[:,i] = forest[i].predict(X_test_sub)\n",
    "    sgd_hybrid.predict(X_test_treefeature)\n",
    "    \n",
    "    train_accuracy = sgd_hybrid.score(X_train_treefeature,y_train)\n",
    "    test_accuracy = sgd_hybrid.score(X_test_treefeature,y_test)\n",
    "    \n",
    "    return train_accuracy, test_accuracy, sgd_hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# When you turn this function in to Gradescope, it is easiest to copy and paste this cell to a new python file called hw1.py\n",
    "# and upload that file instead of the full Jupyter Notebook code (which will cause problems for Gradescope)\n",
    "def compute_features(names):\n",
    "    \"\"\"\n",
    "    Given a list of names of length N, return a numpy matrix of shape (N, 260)\n",
    "    with the features described in problem 2b of the homework assignment.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    names: A list of strings\n",
    "        The names to featurize, e.g. [\"albert einstein\", \"marie curie\"]\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    numpy.array:\n",
    "        A numpy array of shape (N, 260)\n",
    "    \"\"\"\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are not required to use the functions defined below, but they may be useful for you to think about how to structure your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "def train_and_evaluate_sgd(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Trains a SGDClassifier on the training data and computes two accuracy scores, the\n",
    "    accuracy of the classifier on the training data and the accuracy of the decision\n",
    "    tree on the testing data.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: np.array\n",
    "        The training features of shape (N_train, k)\n",
    "    y_train: np.array\n",
    "        The training labels of shape (N_train)\n",
    "    X_test: np.array\n",
    "        The testing features of shape (N_test, k)\n",
    "    y_test: np.array\n",
    "        The testing labels of shape (N_test)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The training, testing accuracies, and the trained sgd model represented as a tuple of size 3.\n",
    "    \"\"\"\n",
    "    \n",
    "    sgd_model = SGDClassifier(loss = 'log', max_iter = 10000)\n",
    "    sgd_model = sgd_model.fit(X_train,y_train)\n",
    "    sgd_model.predict(X_test)\n",
    "    \n",
    "    \n",
    "    return 0.0, 0.0, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "def train_and_evaluate_decision_tree(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Trains an unbounded decision tree on the training data and computes two accuracy scores, the\n",
    "    accuracy of the decision tree on the training data and the accuracy of the decision\n",
    "    tree on the testing data.\n",
    "    \n",
    "    The decision tree should use the information gain criterion (set criterion='entropy')\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: np.array\n",
    "        The training features of shape (N_train, k)\n",
    "    y_train: np.array\n",
    "        The training labels of shape (N_train)\n",
    "    X_test: np.array\n",
    "        The testing features of shape (N_test, k)\n",
    "    y_test: np.array\n",
    "        The testing labels of shape (N_test)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The training, testing accuracies, and the trained decision tree model represented as a tuple of size 3.\n",
    "    \"\"\"\n",
    "    \n",
    "    dectree_model = DecisionTreeClassifier(criterion='entropy')\n",
    "    \n",
    "    \n",
    "    return 0.0, 0.0, None\n",
    "\n",
    "\n",
    "def train_and_evaluate_decision_stump(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Trains a decision stump of maximum depth 4 on the training data and computes two accuracy scores, the\n",
    "    accuracy of the decision stump on the training data and the accuracy of the decision\n",
    "    tree on the testing data.\n",
    "    \n",
    "    The decision tree should use the information gain criterion (set criterion='entropy')\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: np.array\n",
    "        The training features of shape (N_train, k)\n",
    "    y_train: np.array\n",
    "        The training labels of shape (N_train)\n",
    "    X_test: np.array\n",
    "        The testing features of shape (N_test, k)\n",
    "    y_test: np.array\n",
    "        The testing labels of shape (N_test)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The training, testing, the trained stump model accuracies represented as a tuple of size 3.\n",
    "    \"\"\"\n",
    "    \n",
    "    decstump_model = DecisionTreeClassifier(criterion='entropy', max_depth=4)\n",
    "    \n",
    "    \n",
    "    return 0.0, 0.0, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_sgd_with_stumps(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Trains a SGDClassifier with stumps on the training data and computes two accuracy scores, the\n",
    "    accuracy of the classifier on the training data and the accuracy of the decision\n",
    "    tree on the testing data.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: np.array\n",
    "        The training features of shape (N_train, k)\n",
    "    y_train: np.array\n",
    "        The training labels of shape (N_train)\n",
    "    X_test: np.array\n",
    "        The testing features of shape (N_test, k)\n",
    "    y_test: np.array\n",
    "        The testing labels of shape (N_test)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The training, testing accuracies, and the trained model represented as a tuple of size 3.\n",
    "    \"\"\"\n",
    "    \n",
    "#     k = X_train.shape[1]      #number of features\n",
    "#     tree_num = 100      #number of trees as features\n",
    "#     # initialize a N by tree_num as new X_train made of outputs from 100 trees\n",
    "#     X_train_treefeature = np.empty([X_train.shape[0],tree_num])   \n",
    "#     forest = []\n",
    "#     feature_indexes = np.empty([tree_num,int(k/2)])\n",
    "#     for i in range(tree_num):\n",
    "#         index_vec = list(range(k))\n",
    "#         for j in range(int(k/2)):\n",
    "#             index_vec.pop(random.randrange(0,int(k/2)))\n",
    "#         X_train_sub = np.delete(X_train,index_vec,1)\n",
    "#         newstump = DecisionTreeClassifier(criterion='entropy',max_depth=4)\n",
    "#         newstump = newstump.fit(X_train_sub,y_train)\n",
    "#         X_train_treefeature[:,i] = newstump.predict(X_train_sub)   #output x predictions\n",
    "#         forest.append(newstump)     #output new tree stump classifier\n",
    "#         feature_indexes[i,:] = index_vec      #output feature indexes for this tree\n",
    "\n",
    "#     # apply the stump modified X_train to the sgd classifier\n",
    "#     sgd_hybrid = SGDClassifier(loss = 'log', max_iter = 10000)\n",
    "#     sgd_hybrid = sgd_hybrid.fit(X_train_treefeature,y_train)\n",
    "\n",
    "    \n",
    "    return 0.0, 0.0, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cv_split(fold):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    fold: int\n",
    "        The integer index of the split to load, i.e. 0, 1, 2, 3, or 4\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    A tuple of 4 numpy arrays that correspond to the following items:\n",
    "        X_train, y_train, X_test, y_test\n",
    "    \"\"\"\n",
    "    return None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_results(sgd_train_acc, sgd_train_std, sgd_heldout_acc, sgd_heldout_std, sgd_test_acc,\n",
    "                 dt_train_acc, dt_train_std, dt_heldout_acc, dt_heldout_std, dt_test_acc,\n",
    "                 dt4_train_acc, dt4_train_std, dt4_heldout_acc, dt4_heldout_std, dt4_test_acc,\n",
    "                 stumps_train_acc, stumps_train_std, stumps_heldout_acc, stumps_heldout_std, stumps_test_acc):\n",
    "    \"\"\"\n",
    "    Plots the final results from problem 2. For each of the 4 classifiers, pass\n",
    "    the training accuracy, training standard deviation, held-out accuracy, held-out\n",
    "    standard deviation, and testing accuracy.\n",
    "\n",
    "    Although it should not be necessary, feel free to edit this method.\n",
    "    \"\"\"\n",
    "    train_x_pos = [0, 4, 8, 12]\n",
    "    cv_x_pos = [1, 5, 9, 13]\n",
    "    test_x_pos = [2, 6, 10, 14]\n",
    "    ticks = cv_x_pos\n",
    "\n",
    "    labels = ['sgd', 'dt', 'dt4', 'stumps (4 x 50)']\n",
    "\n",
    "    train_accs = [sgd_train_acc, dt_train_acc, dt4_train_acc, stumps_train_acc]\n",
    "    train_errors = [sgd_train_std, dt_train_std, dt4_train_std, stumps_train_std]\n",
    "\n",
    "    cv_accs = [sgd_heldout_acc, dt_heldout_acc, dt4_heldout_acc, stumps_heldout_acc]\n",
    "    cv_errors = [sgd_heldout_std, dt_heldout_std, dt4_heldout_std, stumps_heldout_std]\n",
    "\n",
    "    test_accs = [sgd_test_acc, dt_test_acc, dt4_test_acc, stumps_test_acc]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(train_x_pos, train_accs, yerr=train_errors, align='center', alpha=0.5, ecolor='black', capsize=10, label='train')\n",
    "    ax.bar(cv_x_pos, cv_accs, yerr=cv_errors, align='center', alpha=0.5, ecolor='black', capsize=10, label='held-out')\n",
    "    ax.bar(test_x_pos, test_accs, align='center', alpha=0.5, capsize=10, label='test')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_xticks(ticks)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_title('Models')\n",
    "    ax.yaxis.grid(True)\n",
    "    ax.legend()\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(0.6, 0.1, 0.7, 0.1, 0.1,\n",
    "             0.7, 0.2, 0.7, 0.15, 0.2,\n",
    "             0.8, 0.3, 0.7, 0.2, 0.3,\n",
    "             0.9, 0.4, 0.7, 0.25, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_txt_predictions(trained_model, X, filename):\n",
    "    \"\"\"\n",
    "    This function will write the predictions txt files needed for your prediction submissions. You can access \n",
    "    your trained model by following the suggested return values in train_and_evaluate_sgd_with_stumps(). You\n",
    "    should also be careful to write the correct filename as described in the write up.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    trained_model: sklearn.base.BaseEstimator\n",
    "        These are the sklearn models that you trained above on the training data.\n",
    "    X_leaderboard: np.array\n",
    "        The leaderboard features of shape (N_leaderboard, k)\n",
    "    filename: String\n",
    "        This is the name of the resulting txt file.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    predicted_labels = trained_model.predict(X)\n",
    "    np.savetxt(\"{}.txt\".format(filename), predicted_labels, fmt='%i', newline=\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                 Type                      Data/Info\n",
      "------------------------------------------------------------\n",
      "DecisionTreeClassifier   ABCMeta                   <class 'sklearn.tree._cla<...>.DecisionTreeClassifier'>\n",
      "SGDClassifier            ABCMeta                   <class 'sklearn.linear_mo<...>_gradient.SGDClassifier'>\n",
      "X_test                   ndarray                   200x600: 120000 elems, type `float64`, 960000 bytes (937.5 kb)\n",
      "X_test_sub               ndarray                   200x300: 60000 elems, type `float64`, 480000 bytes (468.75 kb)\n",
      "X_test_treefeature       ndarray                   200x100: 20000 elems, type `float64`, 160000 bytes (156.25 kb)\n",
      "X_train                  ndarray                   2100x600: 1260000 elems, type `float64`, 10080000 bytes (9.613037109375 Mb)\n",
      "X_train_sub              ndarray                   2100x300: 630000 elems, type `float64`, 5040000 bytes (4.8065185546875 Mb)\n",
      "X_train_treefeature      ndarray                   2100x100: 210000 elems, type `float64`, 1680000 bytes (1.6021728515625 Mb)\n",
      "decstump_model           DecisionTreeClassifier    DecisionTreeClassifier(criterion='entropy')\n",
      "dectree_model            DecisionTreeClassifier    DecisionTreeClassifier(criterion='entropy')\n",
      "feature_indexes          ndarray                   100x300: 30000 elems, type `float64`, 240000 bytes (234.375 kb)\n",
      "forest                   list                      n=100\n",
      "i                        int                       0\n",
      "index_vec                ndarray                   300: 300 elems, type `float64`, 2400 bytes\n",
      "j                        int                       299\n",
      "k                        int                       600\n",
      "newstump                 DecisionTreeClassifier    DecisionTreeClassifier(cr<...>n='entropy', max_depth=4)\n",
      "np                       module                    <module 'numpy' from 'C:\\<...>ges\\\\numpy\\\\__init__.py'>\n",
      "random                   module                    <module 'random' from 'C:<...>aconda3\\\\lib\\\\random.py'>\n",
      "sgd_hybrid               SGDClassifier             SGDClassifier(loss='log', max_iter=10000)\n",
      "sgd_model                SGDClassifier             SGDClassifier(loss='log', max_iter=10000)\n",
      "temp                     ndarray                   200: 200 elems, type `int64`, 1600 bytes\n",
      "tree_num                 int                       100\n",
      "y_test                   ndarray                   200: 200 elems, type `int64`, 1600 bytes\n",
      "y_train                  ndarray                   2100: 2100 elems, type `int64`, 16800 bytes\n"
     ]
    }
   ],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
