{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1\n",
    "This is the template for the first homework assignment.\n",
    "The only function that you are required to fill in and turn in to Gradescope is \"compute_features\".\n",
    "Please do not edit definition of \"compute_features\" so the Gradescope unit tests run successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment and run this code if you want to verify your `sklearn` installation.\n",
    "# If this cell outputs 'array([1])', then it's installed correctly.\n",
    "\n",
    "# from sklearn import tree\n",
    "# X = [[0, 0], [1, 1]]\n",
    "# y = [0, 1]\n",
    "# clf = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "# clf = clf.fit(X, y)\n",
    "# clf.predict([[2, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"madelon/train/X_train.npy\")\n",
    "y_train = np.load(\"madelon/train/Y_train.npy\")\n",
    "X_test = np.load(\"madelon/test/X_test.npy\")\n",
    "y_test = np.load(\"madelon/test/Y_test.npy\")\n",
    "# X_train1 = np."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sdg_train_accuracy,sdg_test_accuracy,sdg_trained_model = train_and_evaluate_sgd(x_train,y_train,x_test,y_test) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.555\n"
     ]
    }
   ],
   "source": [
    "# sdg model full train and test set\n",
    "\n",
    "sgd_model = SGDClassifier(loss = 'log', max_iter = 10000)\n",
    "sgd_model = sgd_model.fit(X_train,y_train)\n",
    "sgd_model.predict(X_test)\n",
    "sgd_testing_accuracy = sgd_model.score(X_test,y_test)\n",
    "print(sgd_testing_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation of Sgd\n",
    "\n",
    "k = 5\n",
    "acc_train_sgd = np.zeros(k)\n",
    "acc_heldout_sgd = np.zeros(k)\n",
    "for i in range(k):\n",
    "\n",
    "    X_heldout_cv_fileloc = \"madelon/cross_validation/cv-heldout-X.\" + str(i) + \".npy\"\n",
    "    X_heldout_cv = np.load(X_heldout_cv_fileloc)\n",
    "    y_heldout_cv_fileloc = \"madelon/cross_validation/cv-heldout-y.\" + str(i) + \".npy\"\n",
    "    y_heldout_cv = np.load(y_heldout_cv_fileloc)\n",
    "    X_train_cv_fileloc = \"madelon/cross_validation/cv-train-X.\" + str(i) + \".npy\"\n",
    "    X_train_cv = np.load(X_train_cv_fileloc)\n",
    "    y_train_cv_fileloc = \"madelon/cross_validation/cv-train-y.\" + str(i) + \".npy\"\n",
    "    y_train_cv = np.load(y_train_cv_fileloc)\n",
    "\n",
    "    sgd_model = SGDClassifier(loss = 'log', max_iter = 10000)\n",
    "    sgd_model = sgd_model.fit(X_train_cv,y_train_cv)\n",
    "    acc_train_sgd[i] = sgd_model.score(X_train_cv,y_train_cv)\n",
    "    acc_heldout_sgd[i] = sgd_model.score(X_heldout_cv,y_heldout_cv)\n",
    "\n",
    "std_train_sgd = np.std(acc_train_sgd)\n",
    "std_heldout_sgd = np.std(acc_heldout_sgd)\n",
    "acc_train_sgd_avg = np.average(acc_train_sgd)\n",
    "acc_heldout_sgd_avg = np.average(acc_heldout_sgd)\n",
    "CI_train_sgd = [acc_train_sgd_avg - 2.571 * np.std(acc_train_sgd) / np.sqrt(k),\\\n",
    "                acc_train_sgd_avg + 2.571 * np.std(acc_train_sgd) / np.sqrt(k)]\n",
    "CI_heldout_sgd = [acc_heldout_sgd_avg - 2.571 * np.std(acc_heldout_sgd) / np.sqrt(k),\\\n",
    "                  acc_heldout_sgd_avg + 2.571 * np.std(acc_heldout_sgd) / np.sqrt(k)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8047619  0.80297619 0.78452381 0.78333333 0.80416667]\n",
      "[0.63095238 0.61904762 0.57857143 0.53333333 0.62619048]\n",
      "0.795952380952381\n",
      "0.5976190476190476\n",
      "[0.7846368411747484, 0.8072679207300135]\n",
      "[0.554961869215082, 0.6402762260230133]\n"
     ]
    }
   ],
   "source": [
    "print(acc_train_sgd)\n",
    "print(acc_heldout_sgd)\n",
    "print(acc_train_sgd_avg)\n",
    "print(acc_heldout_sgd_avg)\n",
    "print(CI_train_sgd)\n",
    "print(CI_heldout_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65\n"
     ]
    }
   ],
   "source": [
    "# decision tree full train and test set\n",
    "\n",
    "dectree_model = DecisionTreeClassifier(criterion='entropy')\n",
    "dectree_model = dectree_model.fit(X_train,y_train)\n",
    "dectree_model.predict(X_test)\n",
    "dectree_testing_accuracy = dectree_model.score(X_test,y_test)\n",
    "print(dectree_testing_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree cross validation\n",
    "\n",
    "k = 5\n",
    "acc_train_dectree = np.zeros(k)\n",
    "acc_heldout_dectree = np.zeros(k)\n",
    "for i in range(k):\n",
    "    \n",
    "    X_train_cv_fileloc = \"madelon/cross_validation/cv-train-X.\" + str(i) + \".npy\"\n",
    "    X_train_cv = np.load(X_train_cv_fileloc)\n",
    "    y_train_cv_fileloc = \"madelon/cross_validation/cv-train-y.\" + str(i) + \".npy\"\n",
    "    y_train_cv = np.load(y_train_cv_fileloc)\n",
    "    X_heldout_cv_fileloc = \"madelon/cross_validation/cv-heldout-X.\" + str(i) + \".npy\"\n",
    "    X_heldout_cv = np.load(X_heldout_cv_fileloc)\n",
    "    y_heldout_cv_fileloc = \"madelon/cross_validation/cv-heldout-y.\" + str(i) + \".npy\"\n",
    "    y_heldout_cv = np.load(y_heldout_cv_fileloc)\n",
    "    \n",
    "    dectree_model = DecisionTreeClassifier(criterion='entropy')\n",
    "    dectree_model = dectree_model.fit(X_train_cv,y_train_cv)\n",
    "    acc_train_dectree[i] = dectree_model.score(X_train_cv,y_train_cv)\n",
    "    acc_heldout_dectree[i] = dectree_model.score(X_heldout_cv,y_heldout_cv)\n",
    "\n",
    "std_train_dectree = np.std(acc_train_dectree)\n",
    "std_heldout_dectree = np.std(acc_heldout_dectree)\n",
    "acc_train_dectree_avg = np.average(acc_train_dectree)\n",
    "acc_heldout_dectree_avg = np.average(acc_heldout_dectree)\n",
    "CI_train_dectree = [acc_train_dectree_avg - 2.571 * np.std(acc_train_dectree) / np.sqrt(k),\\\n",
    "                acc_train_dectree_avg + 2.571 * np.std(acc_train_dectree) / np.sqrt(k)]\n",
    "CI_heldout_dectree = [acc_heldout_dectree_avg - 2.571 * np.std(acc_heldout_dectree) / np.sqrt(k),\\\n",
    "                  acc_heldout_dectree_avg + 2.571 * np.std(acc_heldout_dectree) / np.sqrt(k)]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "[0.67142857 0.7047619  0.68095238 0.67619048 0.63809524]\n",
      "1.0\n",
      "0.6742857142857143\n",
      "[1.0, 1.0]\n",
      "[0.649653523832354, 0.6989179047390746]\n"
     ]
    }
   ],
   "source": [
    "print(acc_train_dectree)\n",
    "print(acc_heldout_dectree)\n",
    "print(acc_train_dectree_avg)\n",
    "print(acc_heldout_dectree_avg)\n",
    "print(CI_train_dectree)\n",
    "print(CI_heldout_dectree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.645\n"
     ]
    }
   ],
   "source": [
    "# stump decision tree full train and test set\n",
    "\n",
    "decstump_model = DecisionTreeClassifier(criterion='entropy', max_depth=4)\n",
    "decstump_model = dectree_model.fit(X_train,y_train)\n",
    "temp = decstump_model.predict(X_test)\n",
    "decstump_testing_accuracy = decstump_model.score(X_test,y_test)\n",
    "print(decstump_testing_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stump decision tree full cross validation\n",
    "\n",
    "k = 5\n",
    "acc_train_decstump = np.zeros(k)\n",
    "acc_heldout_decstump = np.zeros(k)\n",
    "for i in range(k):\n",
    "    \n",
    "    X_train_cv_fileloc = \"madelon/cross_validation/cv-train-X.\" + str(i) + \".npy\"\n",
    "    X_train_cv = np.load(X_train_cv_fileloc)\n",
    "    y_train_cv_fileloc = \"madelon/cross_validation/cv-train-y.\" + str(i) + \".npy\"\n",
    "    y_train_cv = np.load(y_train_cv_fileloc)\n",
    "    X_heldout_cv_fileloc = \"madelon/cross_validation/cv-heldout-X.\" + str(i) + \".npy\"\n",
    "    X_heldout_cv = np.load(X_heldout_cv_fileloc)\n",
    "    y_heldout_cv_fileloc = \"madelon/cross_validation/cv-heldout-y.\" + str(i) + \".npy\"\n",
    "    y_heldout_cv = np.load(y_heldout_cv_fileloc)\n",
    "    \n",
    "    decstump_model = DecisionTreeClassifier(criterion='entropy', max_depth=4)\n",
    "    decstump_model = decstump_model.fit(X_train_cv,y_train_cv)\n",
    "    acc_train_decstump[i] = decstump_model.score(X_train_cv,y_train_cv)\n",
    "    acc_heldout_decstump[i] = decstump_model.score(X_heldout_cv,y_heldout_cv)\n",
    "\n",
    "std_train_decstump = np.std(acc_train_decstump)\n",
    "std_heldout_decstump = np.std(acc_heldout_decstump)\n",
    "acc_train_decstump_avg = np.average(acc_train_decstump)\n",
    "acc_heldout_decstump_avg = np.average(acc_heldout_decstump)\n",
    "CI_train_decstump = [acc_train_decstump_avg - 2.571 * np.std(acc_train_decstump) / np.sqrt(k),\\\n",
    "                acc_train_decstump_avg + 2.571 * np.std(acc_train_decstump) / np.sqrt(k)]\n",
    "CI_heldout_decstump = [acc_heldout_decstump_avg - 2.571 * np.std(acc_heldout_decstump) / np.sqrt(k),\\\n",
    "                  acc_heldout_decstump_avg + 2.571 * np.std(acc_heldout_decstump) / np.sqrt(k)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76369048 0.74880952 0.75654762 0.76904762 0.76904762]\n",
      "[0.72142857 0.68333333 0.70714286 0.69761905 0.71666667]\n",
      "0.7614285714285713\n",
      "0.7052380952380952\n",
      "[0.7524590595683749, 0.7703980832887678]\n",
      "[0.6895213944366664, 0.7209547960395241]\n"
     ]
    }
   ],
   "source": [
    "print(acc_train_decstump)\n",
    "print(acc_heldout_decstump)\n",
    "print(acc_train_decstump_avg)\n",
    "print(acc_heldout_decstump_avg)\n",
    "print(CI_train_decstump)\n",
    "print(CI_heldout_decstump)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hybrid model training accuracy 0.8642857142857143\n",
      "hybrid model testing accuracy 0.755\n"
     ]
    }
   ],
   "source": [
    "# # hybrid model full train and test set\n",
    "\n",
    "M = X_train.shape[1]      #number of features\n",
    "tree_num = 100      #number of trees as features\n",
    "# initialize a N by tree_num as new X_train made of outputs from 100 trees\n",
    "X_train_treefeature = np.empty([X_train.shape[0],tree_num])   \n",
    "forest = []\n",
    "feature_indexes = np.empty([tree_num,int(M/2)])\n",
    "# train 100 stumps per example as features\n",
    "for i in range(tree_num):\n",
    "    index_vec = list(range(M))\n",
    "    for j in range(int(M/2)):\n",
    "        index_vec.pop(random.randrange(0,int(M/2)))\n",
    "    X_train_sub = np.delete(X_train,index_vec,1)\n",
    "    newstump = DecisionTreeClassifier(criterion='entropy',max_depth=4)\n",
    "    newstump = newstump.fit(X_train_sub,y_train)\n",
    "    X_train_treefeature[:,i] = newstump.predict(X_train_sub)   #output x predictions\n",
    "    forest.append(newstump)     #output new tree stump classifier\n",
    "    feature_indexes[i,:] = index_vec      #output feature indexes for this tree\n",
    "\n",
    "# apply the stump modified X_train to the sgd classifier\n",
    "sgd_hybrid = SGDClassifier(loss = 'log', max_iter = 10000)\n",
    "sgd_hybrid = sgd_hybrid.fit(X_train_treefeature,y_train)\n",
    "\n",
    "# convert X_test to treefeature and test accuracy on test set\n",
    "X_test_treefeature = np.empty([X_test.shape[0],tree_num])\n",
    "index_vec = feature_indexes.astype(int)\n",
    "\n",
    "for i in range(tree_num):\n",
    "    X_test_sub = np.delete(X_test,index_vec[i,:],1)\n",
    "    X_test_treefeature[:,i] = forest[i].predict(X_test_sub)\n",
    "sgd_hybrid.predict(X_test_treefeature)\n",
    "sgd_hybrid_training_accuracy = sgd_hybrid.score(X_train_treefeature,y_train)\n",
    "sgd_hybrid_testing_accuracy = sgd_hybrid.score(X_test_treefeature,y_test)\n",
    "print('hybrid model training accuracy ' + str(sgd_hybrid_training_accuracy))\n",
    "print('hybrid model testing accuracy ' + str(sgd_hybrid_testing_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use hybrid training function to do cross validation\n",
    "\n",
    "k = 5\n",
    "acc_train_hybrid = np.zeros(k)\n",
    "acc_heldout_hybrid = np.zeros(k)\n",
    "for i in range(k):\n",
    "    X_train_cv_fileloc = \"madelon/cross_validation/cv-train-X.\" + str(i) + \".npy\"\n",
    "    X_train_cv = np.load(X_train_cv_fileloc)\n",
    "    y_train_cv_fileloc = \"madelon/cross_validation/cv-train-y.\" + str(i) + \".npy\"\n",
    "    y_train_cv = np.load(y_train_cv_fileloc)\n",
    "    X_heldout_cv_fileloc = \"madelon/cross_validation/cv-heldout-X.\" + str(i) + \".npy\"\n",
    "    X_heldout_cv = np.load(X_heldout_cv_fileloc)\n",
    "    y_heldout_cv_fileloc = \"madelon/cross_validation/cv-heldout-y.\" + str(i) + \".npy\"\n",
    "    y_heldout_cv = np.load(y_heldout_cv_fileloc)\n",
    "    acc_train_hybrid[i],acc_heldout_hybrid[i],sgd_hybrid = train_hybrid_model(X_train_cv,y_train_cv,\\\n",
    "                                                                              X_heldout_cv,y_heldout_cv)\n",
    "\n",
    "std_train_hybrid = np.std(acc_train_hybrid)\n",
    "std_heldout_hybrid = np.std(acc_heldout_hybrid)\n",
    "acc_train_hybrid_avg = np.average(acc_train_hybrid)\n",
    "acc_heldout_hybrid_avg = np.average(acc_heldout_hybrid)\n",
    "CI_train_hybrid = [acc_train_hybrid_avg - 2.571 * np.std(acc_train_hybrid) / np.sqrt(k),\\\n",
    "                acc_train_hybrid_avg + 2.571 * np.std(acc_train_hybrid) / np.sqrt(k)]\n",
    "CI_heldout_hybrid = [acc_heldout_hybrid_avg - 2.571 * np.std(acc_heldout_hybrid) / np.sqrt(k),\\\n",
    "                  acc_heldout_hybrid_avg + 2.571 * np.std(acc_heldout_hybrid) / np.sqrt(k)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85119048 0.86547619 0.88035714 0.87083333 0.8375    ]\n",
      "[0.78571429 0.75238095 0.73571429 0.71666667 0.76666667]\n",
      "0.8610714285714287\n",
      "0.7514285714285714\n",
      "[0.8437109449026399, 0.8784319122402175]\n",
      "[0.7239107243515361, 0.7789464185056068]\n"
     ]
    }
   ],
   "source": [
    "print(acc_train_hybrid)\n",
    "print(acc_heldout_hybrid)\n",
    "print(acc_train_hybrid_avg)\n",
    "print(acc_heldout_hybrid_avg)\n",
    "print(CI_train_hybrid)\n",
    "print(CI_heldout_hybrid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the results\n",
    "\n",
    "plot_results(acc_train_sgd_avg, std_train_sgd, acc_heldout_sgd_avg, std_heldout_sgd, sgd_testing_accuracy,\n",
    "             acc_train_dectree_avg, std_train_dectree, acc_heldout_dectree_avg, std_heldout_dectree, dectree_testing_accuracy,\n",
    "             acc_train_decstump_avg, std_train_decstump, acc_heldout_decstump_avg, std_heldout_decstump, decstump_testing_accuracy,\n",
    "             acc_train_hybrid_avg, std_train_hybrid, acc_heldout_hybrid_avg, std_heldout_hybrid, sgd_hybrid_testing_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import leaderboard data and predict it\n",
    "\n",
    "X_leaderboard = np.load(\"madelon/leaderboard/X_leaderboard.npy\")\n",
    "X_leaderboard_treefeature = np.empty([X_leaderboard.shape[0],100])\n",
    "index_vec = feature_indexes.astype(int)\n",
    "for i in range(tree_num):\n",
    "    X_leaderboard_sub = np.delete(X_leaderboard,index_vec[i,:],1)\n",
    "    X_leaderboard_treefeature[:,i] = forest[i].predict(X_leaderboard_sub)\n",
    "Leaderboard_predict = sgd_hybrid.predict(X_leaderboard_treefeature)\n",
    "filename = 'labels_2a_leaderboard'\n",
    "np.savetxt(\"{}.txt\".format(filename), Leaderboard_predict, fmt='%i', newline=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import hidden data and predict it\n",
    "\n",
    "X_hidden = np.load(\"madelon/hidden/X_hidden.npy\")\n",
    "X_hidden_treefeature = np.empty([X_hidden.shape[0],100])\n",
    "index_vec = feature_indexes.astype(int)\n",
    "for i in range(tree_num):\n",
    "    X_hidden_sub = np.delete(X_hidden,index_vec[i,:],1)\n",
    "    X_hidden_treefeature[:,i] = forest[i].predict(X_hidden_sub)\n",
    "Hidden_predict = sgd_hybrid.predict(X_hidden_treefeature)\n",
    "filename = 'labels_2a_hidden'\n",
    "np.savetxt(\"{}.txt\".format(filename), Hidden_predict, fmt='%i', newline=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_hybrid_model(X_train, y_train, X_test, y_test):\n",
    "    # hybrid model full train and test set\n",
    "\n",
    "    M = X_train.shape[1]      #number of features\n",
    "    tree_num = 100      #number of trees as features\n",
    "    # initialize a N by tree_num as new X_train made of outputs from 100 trees\n",
    "    X_train_treefeature = np.empty([X_train.shape[0],tree_num])   \n",
    "    forest = []\n",
    "    feature_indexes = np.empty([tree_num,int(M/2)])\n",
    "    # train 100 stumps per example as features\n",
    "    for i in range(tree_num):\n",
    "        index_vec = list(range(M))\n",
    "        for j in range(int(M/2)):\n",
    "            index_vec.pop(random.randrange(0,int(M/2)))\n",
    "        X_train_sub = np.delete(X_train,index_vec,1)\n",
    "        newstump = DecisionTreeClassifier(criterion='entropy',max_depth=4)\n",
    "        newstump = newstump.fit(X_train_sub,y_train)\n",
    "        X_train_treefeature[:,i] = newstump.predict(X_train_sub)   #output x predictions\n",
    "        forest.append(newstump)     #output new tree stump classifier\n",
    "        feature_indexes[i,:] = index_vec      #output feature indexes for this tree\n",
    "\n",
    "    # apply the stump modified X_train to the sgd classifier\n",
    "    sgd_hybrid = SGDClassifier(loss = 'log', max_iter = 10000)\n",
    "    sgd_hybrid = sgd_hybrid.fit(X_train_treefeature,y_train)\n",
    "\n",
    "    # convert X_test to treefeature and test accuracy on test set\n",
    "    X_test_treefeature = np.empty([X_test.shape[0],tree_num])\n",
    "    index_vec = feature_indexes.astype(int)\n",
    "\n",
    "    for i in range(tree_num):\n",
    "        X_test_sub = np.delete(X_test,index_vec[i,:],1)\n",
    "        X_test_treefeature[:,i] = forest[i].predict(X_test_sub)\n",
    "    sgd_hybrid.predict(X_test_treefeature)\n",
    "    \n",
    "    train_accuracy = sgd_hybrid.score(X_train_treefeature,y_train)\n",
    "    test_accuracy = sgd_hybrid.score(X_test_treefeature,y_test)\n",
    "    \n",
    "    return train_accuracy, test_accuracy, sgd_hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# When you turn this function in to Gradescope, it is easiest to copy and paste this cell to a new python file called hw1.py\n",
    "# and upload that file instead of the full Jupyter Notebook code (which will cause problems for Gradescope)\n",
    "def compute_features(names):\n",
    "    \"\"\"\n",
    "    Given a list of names of length N, return a numpy matrix of shape (N, 260)\n",
    "    with the features described in problem 2b of the homework assignment.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    names: A list of strings\n",
    "        The names to featurize, e.g. [\"albert einstein\", \"marie curie\"]\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    numpy.array:\n",
    "        A numpy array of shape (N, 260)\n",
    "    \"\"\"\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are not required to use the functions defined below, but they may be useful for you to think about how to structure your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "def train_and_evaluate_sgd(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Trains a SGDClassifier on the training data and computes two accuracy scores, the\n",
    "    accuracy of the classifier on the training data and the accuracy of the decision\n",
    "    tree on the testing data.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: np.array\n",
    "        The training features of shape (N_train, k)\n",
    "    y_train: np.array\n",
    "        The training labels of shape (N_train)\n",
    "    X_test: np.array\n",
    "        The testing features of shape (N_test, k)\n",
    "    y_test: np.array\n",
    "        The testing labels of shape (N_test)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The training, testing accuracies, and the trained sgd model represented as a tuple of size 3.\n",
    "    \"\"\"\n",
    "    \n",
    "    sgd_model = SGDClassifier(loss = 'log', max_iter = 10000)\n",
    "    sgd_model = sgd_model.fit(X_train,y_train)\n",
    "    sgd_model.predict(X_test)\n",
    "    \n",
    "    \n",
    "    return 0.0, 0.0, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "def train_and_evaluate_decision_tree(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Trains an unbounded decision tree on the training data and computes two accuracy scores, the\n",
    "    accuracy of the decision tree on the training data and the accuracy of the decision\n",
    "    tree on the testing data.\n",
    "    \n",
    "    The decision tree should use the information gain criterion (set criterion='entropy')\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: np.array\n",
    "        The training features of shape (N_train, k)\n",
    "    y_train: np.array\n",
    "        The training labels of shape (N_train)\n",
    "    X_test: np.array\n",
    "        The testing features of shape (N_test, k)\n",
    "    y_test: np.array\n",
    "        The testing labels of shape (N_test)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The training, testing accuracies, and the trained decision tree model represented as a tuple of size 3.\n",
    "    \"\"\"\n",
    "    \n",
    "    dectree_model = DecisionTreeClassifier(criterion='entropy')\n",
    "    \n",
    "    \n",
    "    return 0.0, 0.0, None\n",
    "\n",
    "\n",
    "def train_and_evaluate_decision_stump(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Trains a decision stump of maximum depth 4 on the training data and computes two accuracy scores, the\n",
    "    accuracy of the decision stump on the training data and the accuracy of the decision\n",
    "    tree on the testing data.\n",
    "    \n",
    "    The decision tree should use the information gain criterion (set criterion='entropy')\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: np.array\n",
    "        The training features of shape (N_train, k)\n",
    "    y_train: np.array\n",
    "        The training labels of shape (N_train)\n",
    "    X_test: np.array\n",
    "        The testing features of shape (N_test, k)\n",
    "    y_test: np.array\n",
    "        The testing labels of shape (N_test)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The training, testing, the trained stump model accuracies represented as a tuple of size 3.\n",
    "    \"\"\"\n",
    "    \n",
    "    decstump_model = DecisionTreeClassifier(criterion='entropy', max_depth=4)\n",
    "    \n",
    "    \n",
    "    return 0.0, 0.0, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_sgd_with_stumps(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Trains a SGDClassifier with stumps on the training data and computes two accuracy scores, the\n",
    "    accuracy of the classifier on the training data and the accuracy of the decision\n",
    "    tree on the testing data.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: np.array\n",
    "        The training features of shape (N_train, k)\n",
    "    y_train: np.array\n",
    "        The training labels of shape (N_train)\n",
    "    X_test: np.array\n",
    "        The testing features of shape (N_test, k)\n",
    "    y_test: np.array\n",
    "        The testing labels of shape (N_test)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The training, testing accuracies, and the trained model represented as a tuple of size 3.\n",
    "    \"\"\"\n",
    "    \n",
    "#     k = X_train.shape[1]      #number of features\n",
    "#     tree_num = 100      #number of trees as features\n",
    "#     # initialize a N by tree_num as new X_train made of outputs from 100 trees\n",
    "#     X_train_treefeature = np.empty([X_train.shape[0],tree_num])   \n",
    "#     forest = []\n",
    "#     feature_indexes = np.empty([tree_num,int(k/2)])\n",
    "#     for i in range(tree_num):\n",
    "#         index_vec = list(range(k))\n",
    "#         for j in range(int(k/2)):\n",
    "#             index_vec.pop(random.randrange(0,int(k/2)))\n",
    "#         X_train_sub = np.delete(X_train,index_vec,1)\n",
    "#         newstump = DecisionTreeClassifier(criterion='entropy',max_depth=4)\n",
    "#         newstump = newstump.fit(X_train_sub,y_train)\n",
    "#         X_train_treefeature[:,i] = newstump.predict(X_train_sub)   #output x predictions\n",
    "#         forest.append(newstump)     #output new tree stump classifier\n",
    "#         feature_indexes[i,:] = index_vec      #output feature indexes for this tree\n",
    "\n",
    "#     # apply the stump modified X_train to the sgd classifier\n",
    "#     sgd_hybrid = SGDClassifier(loss = 'log', max_iter = 10000)\n",
    "#     sgd_hybrid = sgd_hybrid.fit(X_train_treefeature,y_train)\n",
    "\n",
    "    \n",
    "    return 0.0, 0.0, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cv_split(fold):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    fold: int\n",
    "        The integer index of the split to load, i.e. 0, 1, 2, 3, or 4\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    A tuple of 4 numpy arrays that correspond to the following items:\n",
    "        X_train, y_train, X_test, y_test\n",
    "    \"\"\"\n",
    "    return None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_results(sgd_train_acc, sgd_train_std, sgd_heldout_acc, sgd_heldout_std, sgd_test_acc,\n",
    "                 dt_train_acc, dt_train_std, dt_heldout_acc, dt_heldout_std, dt_test_acc,\n",
    "                 dt4_train_acc, dt4_train_std, dt4_heldout_acc, dt4_heldout_std, dt4_test_acc,\n",
    "                 stumps_train_acc, stumps_train_std, stumps_heldout_acc, stumps_heldout_std, stumps_test_acc):\n",
    "    \"\"\"\n",
    "    Plots the final results from problem 2. For each of the 4 classifiers, pass\n",
    "    the training accuracy, training standard deviation, held-out accuracy, held-out\n",
    "    standard deviation, and testing accuracy.\n",
    "\n",
    "    Although it should not be necessary, feel free to edit this method.\n",
    "    \"\"\"\n",
    "    train_x_pos = [0, 4, 8, 12]\n",
    "    cv_x_pos = [1, 5, 9, 13]\n",
    "    test_x_pos = [2, 6, 10, 14]\n",
    "    ticks = cv_x_pos\n",
    "\n",
    "    labels = ['sgd', 'dt', 'dt4', 'stumps (4 x 50)']\n",
    "\n",
    "    train_accs = [sgd_train_acc, dt_train_acc, dt4_train_acc, stumps_train_acc]\n",
    "    train_errors = [sgd_train_std, dt_train_std, dt4_train_std, stumps_train_std]\n",
    "\n",
    "    cv_accs = [sgd_heldout_acc, dt_heldout_acc, dt4_heldout_acc, stumps_heldout_acc]\n",
    "    cv_errors = [sgd_heldout_std, dt_heldout_std, dt4_heldout_std, stumps_heldout_std]\n",
    "\n",
    "    test_accs = [sgd_test_acc, dt_test_acc, dt4_test_acc, stumps_test_acc]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(train_x_pos, train_accs, yerr=train_errors, align='center', alpha=0.5, ecolor='black', capsize=10, label='train')\n",
    "    ax.bar(cv_x_pos, cv_accs, yerr=cv_errors, align='center', alpha=0.5, ecolor='black', capsize=10, label='held-out')\n",
    "    ax.bar(test_x_pos, test_accs, align='center', alpha=0.5, capsize=10, label='test')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_xticks(ticks)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_title('Models')\n",
    "    ax.yaxis.grid(True)\n",
    "    ax.legend()\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(0.6, 0.1, 0.7, 0.1, 0.1,\n",
    "             0.7, 0.2, 0.7, 0.15, 0.2,\n",
    "             0.8, 0.3, 0.7, 0.2, 0.3,\n",
    "             0.9, 0.4, 0.7, 0.25, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_txt_predictions(trained_model, X, filename):\n",
    "    \"\"\"\n",
    "    This function will write the predictions txt files needed for your prediction submissions. You can access \n",
    "    your trained model by following the suggested return values in train_and_evaluate_sgd_with_stumps(). You\n",
    "    should also be careful to write the correct filename as described in the write up.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    trained_model: sklearn.base.BaseEstimator\n",
    "        These are the sklearn models that you trained above on the training data.\n",
    "    X_leaderboard: np.array\n",
    "        The leaderboard features of shape (N_leaderboard, k)\n",
    "    filename: String\n",
    "        This is the name of the resulting txt file.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    predicted_labels = trained_model.predict(X)\n",
    "    np.savetxt(\"{}.txt\".format(filename), predicted_labels, fmt='%i', newline=\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                 Type                      Data/Info\n",
      "------------------------------------------------------------\n",
      "DecisionTreeClassifier   ABCMeta                   <class 'sklearn.tree._cla<...>.DecisionTreeClassifier'>\n",
      "SGDClassifier            ABCMeta                   <class 'sklearn.linear_mo<...>_gradient.SGDClassifier'>\n",
      "X_test                   ndarray                   200x600: 120000 elems, type `float64`, 960000 bytes (937.5 kb)\n",
      "X_test_sub               ndarray                   200x300: 60000 elems, type `float64`, 480000 bytes (468.75 kb)\n",
      "X_test_treefeature       ndarray                   200x100: 20000 elems, type `float64`, 160000 bytes (156.25 kb)\n",
      "X_train                  ndarray                   2100x600: 1260000 elems, type `float64`, 10080000 bytes (9.613037109375 Mb)\n",
      "X_train_sub              ndarray                   2100x300: 630000 elems, type `float64`, 5040000 bytes (4.8065185546875 Mb)\n",
      "X_train_treefeature      ndarray                   2100x100: 210000 elems, type `float64`, 1680000 bytes (1.6021728515625 Mb)\n",
      "decstump_model           DecisionTreeClassifier    DecisionTreeClassifier(criterion='entropy')\n",
      "dectree_model            DecisionTreeClassifier    DecisionTreeClassifier(criterion='entropy')\n",
      "feature_indexes          ndarray                   100x300: 30000 elems, type `float64`, 240000 bytes (234.375 kb)\n",
      "forest                   list                      n=100\n",
      "i                        int                       0\n",
      "index_vec                ndarray                   300: 300 elems, type `float64`, 2400 bytes\n",
      "j                        int                       299\n",
      "k                        int                       600\n",
      "newstump                 DecisionTreeClassifier    DecisionTreeClassifier(cr<...>n='entropy', max_depth=4)\n",
      "np                       module                    <module 'numpy' from 'C:\\<...>ges\\\\numpy\\\\__init__.py'>\n",
      "random                   module                    <module 'random' from 'C:<...>aconda3\\\\lib\\\\random.py'>\n",
      "sgd_hybrid               SGDClassifier             SGDClassifier(loss='log', max_iter=10000)\n",
      "sgd_model                SGDClassifier             SGDClassifier(loss='log', max_iter=10000)\n",
      "temp                     ndarray                   200: 200 elems, type `int64`, 1600 bytes\n",
      "tree_num                 int                       100\n",
      "y_test                   ndarray                   200: 200 elems, type `int64`, 1600 bytes\n",
      "y_train                  ndarray                   2100: 2100 elems, type `int64`, 16800 bytes\n"
     ]
    }
   ],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
