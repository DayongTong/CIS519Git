{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1\n",
    "This is the template for the first homework assignment.\n",
    "The only function that you are required to fill in and turn in to Gradescope is \"compute_features\".\n",
    "Please do not edit definition of \"compute_features\" so the Gradescope unit tests run successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment and run this code if you want to verify your `sklearn` installation.\n",
    "# If this cell outputs 'array([1])', then it's installed correctly.\n",
    "\n",
    "# from sklearn import tree\n",
    "# X = [[0, 0], [1, 1]]\n",
    "# y = [0, 1]\n",
    "# clf = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "# clf = clf.fit(X, y)\n",
    "# clf.predict([[2, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"madelon/train/X_train.npy\")\n",
    "y_train = np.load(\"madelon/train/Y_train.npy\")\n",
    "X_test = np.load(\"madelon/test/X_test.npy\")\n",
    "y_test = np.load(\"madelon/test/Y_test.npy\")\n",
    "# X_train1 = np."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sdg_train_accuracy,sdg_test_accuracy,sdg_trained_model = train_and_evaluate_sgd(x_train,y_train,x_test,y_test) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use three basic models to predict\n",
    "sgd_model = SGDClassifier(loss = 'log', max_iter = 10000)\n",
    "sgd_model = sgd_model.fit(X_train,y_train)\n",
    "sgd_model.predict(X_test)\n",
    "sgd_model.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(loss='log', max_iter=10000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dectree_model = DecisionTreeClassifier(criterion='entropy')\n",
    "dectree_model = dectree_model.fit(X_train,y_train)\n",
    "dectree_model.predict(X_test)\n",
    "dectree_model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.635"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decstump_model = DecisionTreeClassifier(criterion='entropy', max_depth=4)\n",
    "decstump_model = dectree_model.fit(X_train,y_train)\n",
    "temp = decstump_model.predict(X_test)\n",
    "decstump_model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "k = X_train.shape[1]      #number of features\n",
    "tree_num = 100      #number of trees as features\n",
    "# initialize a N by tree_num as new X_train made of outputs from 100 trees\n",
    "X_train_treefeature = np.empty([X_train.shape[0],tree_num])   \n",
    "forest = []\n",
    "feature_indexes = np.empty([tree_num,int(k/2)])\n",
    "for i in range(tree_num):\n",
    "    index_vec = list(range(k))\n",
    "    for j in range(int(k/2)):\n",
    "        index_vec.pop(random.randrange(0,int(k/2)))\n",
    "    X_train_sub = np.delete(X_train,index_vec,1)\n",
    "    newstump = DecisionTreeClassifier(criterion='entropy',max_depth=4)\n",
    "    newstump = newstump.fit(X_train_sub,y_train)\n",
    "    X_train_treefeature[:,i] = newstump.predict(X_train_sub)   #output x predictions\n",
    "    forest.append(newstump)     #output new tree stump classifier\n",
    "    feature_indexes[i,:] = index_vec      #output feature indexes for this tree\n",
    "\n",
    "# apply the stump modified X_train to the sgd classifier\n",
    "sgd_hybrid = SGDClassifier(loss = 'log', max_iter = 10000)\n",
    "sgd_hybrid = sgd_hybrid.fit(X_train_treefeature,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_treefeature = np.empty([X_test.shape[0],tree_num])\n",
    "index_vec = feature_indexes.astype(int)\n",
    "\n",
    "for i in range(tree_num):\n",
    "    X_test_sub = np.delete(X_test,index_vec[i,:],1)\n",
    "    X_test_treefeature[:,i] = forest[i].predict(X_test_sub)\n",
    "sgd_hybrid.predict(X_test_treefeature)\n",
    "sgd_hybrid.score(X_test_treefeature,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 600)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# When you turn this function in to Gradescope, it is easiest to copy and paste this cell to a new python file called hw1.py\n",
    "# and upload that file instead of the full Jupyter Notebook code (which will cause problems for Gradescope)\n",
    "def compute_features(names):\n",
    "    \"\"\"\n",
    "    Given a list of names of length N, return a numpy matrix of shape (N, 260)\n",
    "    with the features described in problem 2b of the homework assignment.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    names: A list of strings\n",
    "        The names to featurize, e.g. [\"albert einstein\", \"marie curie\"]\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    numpy.array:\n",
    "        A numpy array of shape (N, 260)\n",
    "    \"\"\"\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are not required to use the functions defined below, but they may be useful for you to think about how to structure your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "def train_and_evaluate_sgd(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Trains a SGDClassifier on the training data and computes two accuracy scores, the\n",
    "    accuracy of the classifier on the training data and the accuracy of the decision\n",
    "    tree on the testing data.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: np.array\n",
    "        The training features of shape (N_train, k)\n",
    "    y_train: np.array\n",
    "        The training labels of shape (N_train)\n",
    "    X_test: np.array\n",
    "        The testing features of shape (N_test, k)\n",
    "    y_test: np.array\n",
    "        The testing labels of shape (N_test)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The training, testing accuracies, and the trained sgd model represented as a tuple of size 3.\n",
    "    \"\"\"\n",
    "    \n",
    "    sgd_model = SGDClassifier(loss = 'log', max_iter = 10000)\n",
    "    sgd_model = sgd_model.fit(X_train,y_train)\n",
    "    sgd_model.predict(X_test)\n",
    "    \n",
    "    \n",
    "    return 0.0, 0.0, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "def train_and_evaluate_decision_tree(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Trains an unbounded decision tree on the training data and computes two accuracy scores, the\n",
    "    accuracy of the decision tree on the training data and the accuracy of the decision\n",
    "    tree on the testing data.\n",
    "    \n",
    "    The decision tree should use the information gain criterion (set criterion='entropy')\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: np.array\n",
    "        The training features of shape (N_train, k)\n",
    "    y_train: np.array\n",
    "        The training labels of shape (N_train)\n",
    "    X_test: np.array\n",
    "        The testing features of shape (N_test, k)\n",
    "    y_test: np.array\n",
    "        The testing labels of shape (N_test)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The training, testing accuracies, and the trained decision tree model represented as a tuple of size 3.\n",
    "    \"\"\"\n",
    "    \n",
    "    dectree_model = DecisionTreeClassifier(criterion='entropy')\n",
    "    \n",
    "    \n",
    "    return 0.0, 0.0, None\n",
    "\n",
    "\n",
    "def train_and_evaluate_decision_stump(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Trains a decision stump of maximum depth 4 on the training data and computes two accuracy scores, the\n",
    "    accuracy of the decision stump on the training data and the accuracy of the decision\n",
    "    tree on the testing data.\n",
    "    \n",
    "    The decision tree should use the information gain criterion (set criterion='entropy')\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: np.array\n",
    "        The training features of shape (N_train, k)\n",
    "    y_train: np.array\n",
    "        The training labels of shape (N_train)\n",
    "    X_test: np.array\n",
    "        The testing features of shape (N_test, k)\n",
    "    y_test: np.array\n",
    "        The testing labels of shape (N_test)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The training, testing, the trained stump model accuracies represented as a tuple of size 3.\n",
    "    \"\"\"\n",
    "    \n",
    "    decstump_model = DecisionTreeClassifier(criterion='entropy', max_depth=4)\n",
    "    \n",
    "    \n",
    "    return 0.0, 0.0, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_sgd_with_stumps(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Trains a SGDClassifier with stumps on the training data and computes two accuracy scores, the\n",
    "    accuracy of the classifier on the training data and the accuracy of the decision\n",
    "    tree on the testing data.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: np.array\n",
    "        The training features of shape (N_train, k)\n",
    "    y_train: np.array\n",
    "        The training labels of shape (N_train)\n",
    "    X_test: np.array\n",
    "        The testing features of shape (N_test, k)\n",
    "    y_test: np.array\n",
    "        The testing labels of shape (N_test)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The training, testing accuracies, and the trained model represented as a tuple of size 3.\n",
    "    \"\"\"\n",
    "    \n",
    "#     k = X_train.shape[1]      #number of features\n",
    "#     tree_num = 100      #number of trees as features\n",
    "#     # initialize a N by tree_num as new X_train made of outputs from 100 trees\n",
    "#     X_train_treefeature = np.empty([X_train.shape[0],tree_num])   \n",
    "#     forest = []\n",
    "#     feature_indexes = np.empty([tree_num,int(k/2)])\n",
    "#     for i in range(tree_num):\n",
    "#         index_vec = list(range(k))\n",
    "#         for j in range(int(k/2)):\n",
    "#             index_vec.pop(random.randrange(0,int(k/2)))\n",
    "#         X_train_sub = np.delete(X_train,index_vec,1)\n",
    "#         newstump = DecisionTreeClassifier(criterion='entropy',max_depth=4)\n",
    "#         newstump = newstump.fit(X_train_sub,y_train)\n",
    "#         X_train_treefeature[:,i] = newstump.predict(X_train_sub)   #output x predictions\n",
    "#         forest.append(newstump)     #output new tree stump classifier\n",
    "#         feature_indexes[i,:] = index_vec      #output feature indexes for this tree\n",
    "\n",
    "#     # apply the stump modified X_train to the sgd classifier\n",
    "#     sgd_hybrid = SGDClassifier(loss = 'log', max_iter = 10000)\n",
    "#     sgd_hybrid = sgd_model.fit(X_train_treefeature,y_train)\n",
    "\n",
    "    \n",
    "    return 0.0, 0.0, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cv_split(fold):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    fold: int\n",
    "        The integer index of the split to load, i.e. 0, 1, 2, 3, or 4\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    A tuple of 4 numpy arrays that correspond to the following items:\n",
    "        X_train, y_train, X_test, y_test\n",
    "    \"\"\"\n",
    "    return None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_results(sgd_train_acc, sgd_train_std, sgd_heldout_acc, sgd_heldout_std, sgd_test_acc,\n",
    "                 dt_train_acc, dt_train_std, dt_heldout_acc, dt_heldout_std, dt_test_acc,\n",
    "                 dt4_train_acc, dt4_train_std, dt4_heldout_acc, dt4_heldout_std, dt4_test_acc,\n",
    "                 stumps_train_acc, stumps_train_std, stumps_heldout_acc, stumps_heldout_std, stumps_test_acc):\n",
    "    \"\"\"\n",
    "    Plots the final results from problem 2. For each of the 4 classifiers, pass\n",
    "    the training accuracy, training standard deviation, held-out accuracy, held-out\n",
    "    standard deviation, and testing accuracy.\n",
    "\n",
    "    Although it should not be necessary, feel free to edit this method.\n",
    "    \"\"\"\n",
    "    train_x_pos = [0, 4, 8, 12]\n",
    "    cv_x_pos = [1, 5, 9, 13]\n",
    "    test_x_pos = [2, 6, 10, 14]\n",
    "    ticks = cv_x_pos\n",
    "\n",
    "    labels = ['sgd', 'dt', 'dt4', 'stumps (4 x 50)']\n",
    "\n",
    "    train_accs = [sgd_train_acc, dt_train_acc, dt4_train_acc, stumps_train_acc]\n",
    "    train_errors = [sgd_train_std, dt_train_std, dt4_train_std, stumps_train_std]\n",
    "\n",
    "    cv_accs = [sgd_heldout_acc, dt_heldout_acc, dt4_heldout_acc, stumps_heldout_acc]\n",
    "    cv_errors = [sgd_heldout_std, dt_heldout_std, dt4_heldout_std, stumps_heldout_std]\n",
    "\n",
    "    test_accs = [sgd_test_acc, dt_test_acc, dt4_test_acc, stumps_test_acc]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(train_x_pos, train_accs, yerr=train_errors, align='center', alpha=0.5, ecolor='black', capsize=10, label='train')\n",
    "    ax.bar(cv_x_pos, cv_accs, yerr=cv_errors, align='center', alpha=0.5, ecolor='black', capsize=10, label='held-out')\n",
    "    ax.bar(test_x_pos, test_accs, align='center', alpha=0.5, capsize=10, label='test')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_xticks(ticks)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_title('Models')\n",
    "    ax.yaxis.grid(True)\n",
    "    ax.legend()\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(0.6, 0.1, 0.7, 0.1, 0.1,\n",
    "             0.7, 0.2, 0.7, 0.15, 0.2,\n",
    "             0.8, 0.3, 0.7, 0.2, 0.3,\n",
    "             0.9, 0.4, 0.7, 0.25, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_txt_predictions(trained_model, X, filename):\n",
    "    \"\"\"\n",
    "    This function will write the predictions txt files needed for your prediction submissions. You can access \n",
    "    your trained model by following the suggested return values in train_and_evaluate_sgd_with_stumps(). You\n",
    "    should also be careful to write the correct filename as described in the write up.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    trained_model: sklearn.base.BaseEstimator\n",
    "        These are the sklearn models that you trained above on the training data.\n",
    "    X_leaderboard: np.array\n",
    "        The leaderboard features of shape (N_leaderboard, k)\n",
    "    filename: String\n",
    "        This is the name of the resulting txt file.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    predicted_labels = trained_model.predict(X)\n",
    "    np.savetxt(\"{}.txt\".format(filename), predicted_labels, fmt='%i', newline=\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                 Type                      Data/Info\n",
      "------------------------------------------------------------\n",
      "DecisionTreeClassifier   ABCMeta                   <class 'sklearn.tree._cla<...>.DecisionTreeClassifier'>\n",
      "SGDClassifier            ABCMeta                   <class 'sklearn.linear_mo<...>_gradient.SGDClassifier'>\n",
      "X_test                   ndarray                   200x600: 120000 elems, type `float64`, 960000 bytes (937.5 kb)\n",
      "X_test_sub               ndarray                   200x300: 60000 elems, type `float64`, 480000 bytes (468.75 kb)\n",
      "X_test_treefeature       ndarray                   200x100: 20000 elems, type `float64`, 160000 bytes (156.25 kb)\n",
      "X_train                  ndarray                   2100x600: 1260000 elems, type `float64`, 10080000 bytes (9.613037109375 Mb)\n",
      "X_train_sub              ndarray                   2100x300: 630000 elems, type `float64`, 5040000 bytes (4.8065185546875 Mb)\n",
      "X_train_treefeature      ndarray                   2100x100: 210000 elems, type `float64`, 1680000 bytes (1.6021728515625 Mb)\n",
      "decstump_model           DecisionTreeClassifier    DecisionTreeClassifier(criterion='entropy')\n",
      "dectree_model            DecisionTreeClassifier    DecisionTreeClassifier(criterion='entropy')\n",
      "feature_indexes          ndarray                   100x300: 30000 elems, type `float64`, 240000 bytes (234.375 kb)\n",
      "forest                   list                      n=100\n",
      "i                        int                       0\n",
      "index_vec                ndarray                   300: 300 elems, type `float64`, 2400 bytes\n",
      "j                        int                       299\n",
      "k                        int                       600\n",
      "newstump                 DecisionTreeClassifier    DecisionTreeClassifier(cr<...>n='entropy', max_depth=4)\n",
      "np                       module                    <module 'numpy' from 'C:\\<...>ges\\\\numpy\\\\__init__.py'>\n",
      "random                   module                    <module 'random' from 'C:<...>aconda3\\\\lib\\\\random.py'>\n",
      "sgd_hybrid               SGDClassifier             SGDClassifier(loss='log', max_iter=10000)\n",
      "sgd_model                SGDClassifier             SGDClassifier(loss='log', max_iter=10000)\n",
      "temp                     ndarray                   200: 200 elems, type `int64`, 1600 bytes\n",
      "tree_num                 int                       100\n",
      "y_test                   ndarray                   200: 200 elems, type `int64`, 1600 bytes\n",
      "y_train                  ndarray                   2100: 2100 elems, type `int64`, 16800 bytes\n"
     ]
    }
   ],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
